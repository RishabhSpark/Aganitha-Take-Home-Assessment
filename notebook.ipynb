{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9d0b6993",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "from typing import List, Dict, Any, Optional\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "80a5448e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up logging\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1733a33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to fetch PubMed IDs based on a search query\n",
    "# def fetch_paper_ids_from_pubmed(query: str, max_results: int = 10) -> List[str]:\n",
    "#     base_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi\"\n",
    "#     params = {\n",
    "#         'db': 'pubmed',\n",
    "#         'term': query,\n",
    "#         'retmax': max_results,  # Limit the number of results\n",
    "#         'usehistory': 'y',      # Use history for retrieving large result sets\n",
    "#         'retmode': 'xml'\n",
    "#     }\n",
    "\n",
    "#     # Send the request to fetch paper IDs\n",
    "#     response = requests.get(base_url, params=params)\n",
    "    \n",
    "#     if response.status_code == 200:\n",
    "#         # Parse the XML response to extract paper IDs\n",
    "#         root = ET.fromstring(response.content)\n",
    "        \n",
    "#         # Extract the list of paper IDs from the XML response\n",
    "#         id_list = [id_tag.text for id_tag in root.findall(\".//Id\")]\n",
    "        \n",
    "#         return id_list\n",
    "#     else:\n",
    "#         print(f\"Error fetching paper IDs: {response.status_code}\")\n",
    "#         return []\n",
    "\n",
    "# Function to fetch PubMed IDs based on a search query\n",
    "def fetch_paper_ids_from_pubmed(query: str, max_results: int = 10) -> List[str]:\n",
    "    base_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi\"\n",
    "    params = {\n",
    "        'db': 'pubmed',\n",
    "        'term': query,\n",
    "        'retmax': max_results,  # Limit the number of results\n",
    "        'usehistory': 'y',      # Use history for retrieving large result sets\n",
    "        'retmode': 'xml'\n",
    "    }\n",
    "\n",
    "    # Log the query and parameters\n",
    "    logging.debug(f\"Fetching PubMed IDs for query: {query} with parameters: {params}\")\n",
    "\n",
    "    try:\n",
    "        # Send the request to fetch paper IDs\n",
    "        response = requests.get(base_url, params=params)\n",
    "\n",
    "        # Check if the response status is successful\n",
    "        if response.status_code == 200:\n",
    "            logging.info(f\"Successfully fetched paper IDs for query: {query}\")\n",
    "            \n",
    "            # Parse the XML response to extract paper IDs\n",
    "            root = ET.fromstring(response.content)\n",
    "            \n",
    "            # Extract the list of paper IDs from the XML response\n",
    "            id_list = [id_tag.text for id_tag in root.findall(\".//Id\")]\n",
    "\n",
    "            logging.debug(f\"Fetched {len(id_list)} paper IDs\")\n",
    "            return id_list\n",
    "        else:\n",
    "            logging.error(f\"Error fetching paper IDs: {response.status_code}\")\n",
    "            return []\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        # Log the error if the request fails\n",
    "        logging.error(f\"Request failed: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "84f71728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to send the request and get the paper's XML data\n",
    "# def fetch_xml_data(pubmed_id: str) -> Optional[ET.Element]:\n",
    "#     base_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi\"\n",
    "#     params = {\n",
    "#         'db': 'pubmed',\n",
    "#         'id': pubmed_id,\n",
    "#         'retmode': 'xml'\n",
    "#     }\n",
    "\n",
    "#     try:\n",
    "#         # Send the request to fetch detailed paper information\n",
    "#         response = requests.get(base_url, params=params)\n",
    "#         response.raise_for_status()  # Raise an exception for HTTP errors\n",
    "        \n",
    "#         if response.status_code == 200:\n",
    "#             return ET.fromstring(response.content)  # Return the XML root element\n",
    "#         else:\n",
    "#             print(f\"Error fetching paper details for PubMed ID {pubmed_id}: {response.status_code}\")\n",
    "#             return None\n",
    "#     except requests.exceptions.RequestException as e:\n",
    "#         print(f\"Request failed: {e}\")\n",
    "#         return None\n",
    "\n",
    "# Function to send the request and get the paper's XML data\n",
    "def fetch_xml_data(pubmed_id: str) -> Optional[ET.Element]:\n",
    "    base_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi\"\n",
    "    params = {\n",
    "        'db': 'pubmed',\n",
    "        'id': pubmed_id,\n",
    "        'retmode': 'xml'\n",
    "    }\n",
    "\n",
    "    # Log the request details\n",
    "    logging.debug(f\"Fetching XML data for PubMed ID: {pubmed_id} with parameters: {params}\")\n",
    "\n",
    "    try:\n",
    "        # Send the request to fetch detailed paper information\n",
    "        response = requests.get(base_url, params=params)\n",
    "        response.raise_for_status()  # Raise an exception for HTTP errors\n",
    "        \n",
    "        # Check if the response status is successful\n",
    "        if response.status_code == 200:\n",
    "            logging.info(f\"Successfully fetched XML data for PubMed ID: {pubmed_id}\")\n",
    "            return ET.fromstring(response.content)  # Return the XML root element\n",
    "        else:\n",
    "            logging.error(f\"Error fetching paper details for PubMed ID {pubmed_id}: {response.status_code}\")\n",
    "            return None\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        # Log the error if the request fails\n",
    "        logging.error(f\"Request failed for PubMed ID {pubmed_id}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f8911fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of academic keywords to exclude\n",
    "academic_keywords = [\n",
    "    \"University\", \"College\", \"Institute\", \"Academy\", \"School\", \n",
    "    \"Faculty\", \"Academician\", \"PhD\", \"Professor\",\n",
    "]\n",
    "\n",
    "# Function to check if an affiliation is academic\n",
    "def is_academic(affiliation: str, academic_keywords = List[str]) -> bool:\n",
    "    logging.debug(f\"Checking affiliation: {affiliation}\")\n",
    "    for keyword in academic_keywords:\n",
    "        if keyword.lower() in affiliation.lower():\n",
    "            return True\n",
    "        \n",
    "    logging.info(f\"Affiliation '{affiliation}' is not academic.\")\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "90278857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of pharmaceutical and biotech-related keywords to identify relevant companies\n",
    "pharma_biotech_keywords = [\n",
    "    \"Pharmaceutical\", \"Biotech\", \"Biotechnology\", \"Pharma\", \"Biopharma\", \n",
    "    \"Med\", \"Healthcare\", \"Bio\", \"Genetics\", \"Drug\", \"Therapeutics\", \"Vaccine\",\n",
    "    \"Diagnostics\", \"Clinical\", \"Development\", \"Manufacturing\"\n",
    "]\n",
    "\n",
    "# Function to check if an affiliation is related to pharmaceutical or biotech companies\n",
    "def is_pharma_biotech(affiliation: str, pharma_biotech_keywords = List[str]) -> bool:\n",
    "    logging.debug(f\"Checking affiliation: {affiliation}\")\n",
    "\n",
    "    for keyword in pharma_biotech_keywords:\n",
    "        if keyword.lower() in affiliation.lower():\n",
    "            return True\n",
    "        \n",
    "    logging.info(f\"Affiliation is not related to pharma/biotech: {affiliation}\")\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7657c477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract PubMed ID\n",
    "def get_pubmed_id(root: ET.Element, pubmed_id: str) -> str:\n",
    "    logging.debug(f\"Extracting PubMed ID: {pubmed_id}\")\n",
    "    return pubmed_id\n",
    "\n",
    "\n",
    "# Function to extract the title of the paper\n",
    "def get_title(root: ET.Element) -> str:\n",
    "    title_tag = root.find(\".//ArticleTitle\")\n",
    "    if title_tag is not None:\n",
    "        logging.info(f\"Title extracted: {title_tag.text}\")\n",
    "        return title_tag.text\n",
    "    else:\n",
    "        logging.warning(\"Title not found in the XML.\")\n",
    "        return \"N/A\"\n",
    "\n",
    "\n",
    "# Function to extract the publication date\n",
    "def get_publication_date(root: ET.Element) -> str:\n",
    "    pub_date_tag = root.find(\".//PubDate\")\n",
    "    if pub_date_tag is not None:\n",
    "        year = pub_date_tag.find(\"Year\")\n",
    "        month = pub_date_tag.find(\"Month\")\n",
    "        day = pub_date_tag.find(\"Day\")\n",
    "        if year is not None and month is not None and day is not None:\n",
    "            date = f\"{year.text}-{month.text}-{day.text}\"\n",
    "            logging.info(f\"Publication date extracted: {date}\")\n",
    "            return date\n",
    "        else:\n",
    "            logging.warning(\"Incomplete publication date found (missing year, month, or day).\")\n",
    "            return \"N/A\"\n",
    "    else:\n",
    "        logging.warning(\"Publication date not found in the XML.\")\n",
    "        return \"N/A\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9611ca46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract authors\n",
    "def get_authors(root: ET.Element, academic_keywords: List[str]) -> List[str]:\n",
    "    logging.debug(\"Extracting authors from the XML data.\")\n",
    "\n",
    "    authors_tag = root.findall(\".//AuthorList/Author\")\n",
    "    authors = []\n",
    "    for author in authors_tag:\n",
    "        last_name = author.find(\"LastName\")\n",
    "        fore_name = author.find(\"ForeName\")\n",
    "        affiliation_info = author.findall(\".//AffiliationInfo/Affiliation\")\n",
    "        \n",
    "        # Log the author information for debugging\n",
    "        logging.debug(f\"Processing author: {fore_name.text if fore_name is not None else 'N/A'} {last_name.text if last_name is not None else 'N/A'}\")\n",
    "\n",
    "        # Get the affiliations and check if they are non-academic\n",
    "        if affiliation_info:\n",
    "            for aff in affiliation_info:\n",
    "                logging.debug(f\"Checking affiliation: {aff.text if aff is not None else 'N/A'}\")\n",
    "                if aff is not None and not is_academic(aff.text, academic_keywords):\n",
    "                    if last_name is not None and fore_name is not None:\n",
    "                        author_name = f\"{fore_name.text} {last_name.text}\"\n",
    "                        logging.info(f\"Adding author: {author_name}\")\n",
    "                        authors.append(author_name)\n",
    "                    break\n",
    "        else:\n",
    "            # If no affiliation is found, consider it as non-academic (fallback case)\n",
    "            if last_name is not None and fore_name is not None:\n",
    "                author_name = f\"{fore_name.text} {last_name.text}\"\n",
    "                logging.info(f\"Adding author: {author_name}\")\n",
    "                authors.append(author_name)\n",
    "    \n",
    "    if authors:\n",
    "        logging.debug(f\"Authors extracted: {authors}\")\n",
    "    else:\n",
    "        logging.debug(\"No authors found.\")\n",
    "\n",
    "    return authors if authors else [\"N/A\"]\n",
    "\n",
    "\n",
    "# Function to extract company affiliations\n",
    "# def get_company_affiliations(root):\n",
    "#     affiliations = []\n",
    "#     authors_tag = root.findall(\".//AuthorList/Author\")\n",
    "    \n",
    "#     # Regex pattern to match and remove email and address\n",
    "#     email_pattern = r\"[\\w\\.-]+@[\\w\\.-]+\"\n",
    "#     address_pattern = r\"\\d{5},? \\w+,\\s?[A-Za-z\\s]+\"\n",
    "\n",
    "#     for author in authors_tag:\n",
    "#         aff_info = author.findall(\".//AffiliationInfo/Affiliation\")\n",
    "#         for aff in aff_info:\n",
    "#             if aff is not None:\n",
    "#                 affiliation = aff.text\n",
    "                \n",
    "#                 # Remove email and address from affiliation string\n",
    "#                 affiliation = re.sub(email_pattern, '', affiliation)  # Remove emails\n",
    "#                 affiliation = re.sub(address_pattern, '', affiliation)  # Remove address\n",
    "                \n",
    "#                 # If there's still a valid affiliation left, add it\n",
    "#                 if affiliation.strip():\n",
    "#                     affiliations.append(affiliation.strip())\n",
    "    \n",
    "#     return affiliations if affiliations else [\"N/A\"]\n",
    "\n",
    "# Regex pattern to match and remove email addresses\n",
    "email_pattern = r\"[\\w\\.-]+@[\\w\\.-]+\"\n",
    "\n",
    "def get_pharma_biotech_affiliations(root: ET.Element, pharma_biotech_keywords: List[str], academic_keywords: List[str]) -> List[str]:\n",
    "    logging.debug(\"Extracting pharma/biotech affiliations from the XML data.\")\n",
    "    pharma_biotech_affiliations = []\n",
    "    authors_tag = root.findall(\".//AuthorList/Author\")\n",
    "    \n",
    "    for author in authors_tag:\n",
    "        aff_info = author.findall(\".//AffiliationInfo/Affiliation\")\n",
    "        for aff in aff_info:\n",
    "            if aff is not None:\n",
    "                logging.debug(f\"Checking affiliation: {aff.text}\")\n",
    "                \n",
    "                if is_pharma_biotech(aff.text, pharma_biotech_keywords) and not is_academic(aff.text, academic_keywords):\n",
    "                    # Remove email from affiliation text\n",
    "                    clean_affiliation = re.sub(email_pattern, '', aff.text).strip()\n",
    "                    \n",
    "                    if clean_affiliation:  # Ensure there's something left after removing emails\n",
    "                        logging.info(f\"Adding pharma/biotech affiliation: {clean_affiliation}\")\n",
    "                        pharma_biotech_affiliations.append(clean_affiliation)\n",
    "    \n",
    "    if pharma_biotech_affiliations:\n",
    "        logging.debug(f\"Pharma/Biotech affiliations extracted: {pharma_biotech_affiliations}\")\n",
    "    else:\n",
    "        logging.debug(\"No pharma/biotech affiliations found.\")\n",
    "\n",
    "    return set(pharma_biotech_affiliations) if pharma_biotech_affiliations else [\"N/A\"]\n",
    "\n",
    "\n",
    "\n",
    "# Function to extract corresponding author email\n",
    "def get_corresponding_email(root: ET.Element, academic_keywords: List[str]) -> List[str]:\n",
    "    corresponding_email = None\n",
    "    \n",
    "    # Find authors\n",
    "    authors_tag = root.findall(\".//AuthorList/Author\")\n",
    "    for author in authors_tag:\n",
    "        # Extract the affiliation info\n",
    "        aff_info = author.findall(\".//AffiliationInfo/Affiliation\")\n",
    "        for aff in aff_info:\n",
    "            if aff is not None:\n",
    "                # Split the affiliation text and get the last part (email)\n",
    "                email = aff.text.split()[-1] if aff.text else \"N/A\"\n",
    "                if \"@\" in email:  # Check if it's a valid email\n",
    "                    # Check if the affiliation belongs to a non-academic institution\n",
    "                    if not is_academic(aff.text, academic_keywords):\n",
    "                        corresponding_email = email\n",
    "                        break  # Exit after finding the first non-academic email\n",
    "    \n",
    "    return corresponding_email if corresponding_email else \"N/A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df0d9cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to orchestrate the extraction\n",
    "def fetch_paper_details(pubmed_id: str) -> Dict[str, Any]:\n",
    "    # Get XML data from PubMed\n",
    "    root = fetch_xml_data(pubmed_id)\n",
    "    \n",
    "    if root is None:\n",
    "        return {}\n",
    "\n",
    "    paper_details = {}\n",
    "    \n",
    "    paper_details['PubMedID'] = get_pubmed_id(root, pubmed_id)\n",
    "    paper_details['Title'] = get_title(root)\n",
    "    paper_details['PublicationDate'] = get_publication_date(root)\n",
    "    paper_details['Authors'] = get_authors(root, academic_keywords)\n",
    "    # paper_details['CompanyAffiliations'] = get_company_affiliations(root)\n",
    "    paper_details['CompanyAffiliations'] = get_pharma_biotech_affiliations(root, pharma_biotech_keywords, academic_keywords)\n",
    "    paper_details['CorrespondingAuthorEmail'] = get_corresponding_email(root, academic_keywords)\n",
    "\n",
    "    return paper_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "903c8bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch all paper details based on a query\n",
    "def fetch_all_papers(query: str, max_results: int = 10) -> List[Dict[str, Any]]:\n",
    "    # Fetch the paper IDs\n",
    "    paper_ids = fetch_paper_ids_from_pubmed(query, max_results)\n",
    "\n",
    "    # Fetch the details for each paper using the paper IDs\n",
    "    all_paper_details = []\n",
    "    for pubmed_id in paper_ids:\n",
    "        paper_details = fetch_paper_details(pubmed_id)\n",
    "        all_paper_details.append(paper_details)\n",
    "\n",
    "    return all_paper_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b10f3563",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-10 02:51:57,895 - DEBUG - Starting new HTTPS connection (1): eutils.ncbi.nlm.nih.gov:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-10 02:51:59,489 - DEBUG - https://eutils.ncbi.nlm.nih.gov:443 \"GET /entrez/eutils/esearch.fcgi?db=pubmed&term=healthcare+burnout&retmax=10&usehistory=y&retmode=xml HTTP/11\" 200 None\n",
      "2025-04-10 02:51:59,505 - DEBUG - Starting new HTTPS connection (1): eutils.ncbi.nlm.nih.gov:443\n",
      "2025-04-10 02:52:00,319 - DEBUG - https://eutils.ncbi.nlm.nih.gov:443 \"GET /entrez/eutils/efetch.fcgi?db=pubmed&id=40202386&retmode=xml HTTP/11\" 200 None\n",
      "2025-04-10 02:52:00,513 - DEBUG - Starting new HTTPS connection (1): eutils.ncbi.nlm.nih.gov:443\n",
      "2025-04-10 02:52:01,299 - DEBUG - https://eutils.ncbi.nlm.nih.gov:443 \"GET /entrez/eutils/efetch.fcgi?db=pubmed&id=40200377&retmode=xml HTTP/11\" 200 None\n",
      "2025-04-10 02:52:01,529 - DEBUG - Starting new HTTPS connection (1): eutils.ncbi.nlm.nih.gov:443\n",
      "2025-04-10 02:52:02,310 - DEBUG - https://eutils.ncbi.nlm.nih.gov:443 \"GET /entrez/eutils/efetch.fcgi?db=pubmed&id=40198009&retmode=xml HTTP/11\" 200 None\n",
      "2025-04-10 02:52:02,562 - DEBUG - Starting new HTTPS connection (1): eutils.ncbi.nlm.nih.gov:443\n",
      "2025-04-10 02:52:03,313 - DEBUG - https://eutils.ncbi.nlm.nih.gov:443 \"GET /entrez/eutils/efetch.fcgi?db=pubmed&id=40197340&retmode=xml HTTP/11\" 200 None\n",
      "2025-04-10 02:52:03,535 - DEBUG - Starting new HTTPS connection (1): eutils.ncbi.nlm.nih.gov:443\n",
      "2025-04-10 02:52:04,292 - DEBUG - https://eutils.ncbi.nlm.nih.gov:443 \"GET /entrez/eutils/efetch.fcgi?db=pubmed&id=40197254&retmode=xml HTTP/11\" 200 None\n",
      "2025-04-10 02:52:04,530 - DEBUG - Starting new HTTPS connection (1): eutils.ncbi.nlm.nih.gov:443\n",
      "2025-04-10 02:52:05,284 - DEBUG - https://eutils.ncbi.nlm.nih.gov:443 \"GET /entrez/eutils/efetch.fcgi?db=pubmed&id=40195860&retmode=xml HTTP/11\" 200 None\n",
      "2025-04-10 02:52:05,459 - DEBUG - Starting new HTTPS connection (1): eutils.ncbi.nlm.nih.gov:443\n",
      "2025-04-10 02:52:06,217 - DEBUG - https://eutils.ncbi.nlm.nih.gov:443 \"GET /entrez/eutils/efetch.fcgi?db=pubmed&id=40193343&retmode=xml HTTP/11\" 200 None\n",
      "2025-04-10 02:52:06,445 - DEBUG - Starting new HTTPS connection (1): eutils.ncbi.nlm.nih.gov:443\n",
      "2025-04-10 02:52:07,196 - DEBUG - https://eutils.ncbi.nlm.nih.gov:443 \"GET /entrez/eutils/efetch.fcgi?db=pubmed&id=40190891&retmode=xml HTTP/11\" 200 None\n",
      "2025-04-10 02:52:07,196 - DEBUG - Starting new HTTPS connection (1): eutils.ncbi.nlm.nih.gov:443\n",
      "2025-04-10 02:52:07,973 - DEBUG - https://eutils.ncbi.nlm.nih.gov:443 \"GET /entrez/eutils/efetch.fcgi?db=pubmed&id=40189789&retmode=xml HTTP/11\" 200 None\n",
      "2025-04-10 02:52:08,158 - DEBUG - Starting new HTTPS connection (1): eutils.ncbi.nlm.nih.gov:443\n",
      "2025-04-10 02:52:08,925 - DEBUG - https://eutils.ncbi.nlm.nih.gov:443 \"GET /entrez/eutils/efetch.fcgi?db=pubmed&id=40189735&retmode=xml HTTP/11\" 200 None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'PubMedID': '40202386',\n",
       "  'Title': 'Antecedents and Outcomes of Physician Coworker Conflict: A Differential Occupational Model for Health Care Managers.',\n",
       "  'PublicationDate': '2025-Apr-10',\n",
       "  'Authors': ['N/A'],\n",
       "  'CompanyAffiliations': ['N/A'],\n",
       "  'CorrespondingAuthorEmail': 'N/A'},\n",
       " {'PubMedID': '40200377',\n",
       "  'Title': 'Compassion fatigue in helping professions: a scoping literature review.',\n",
       "  'PublicationDate': '2025-Apr-08',\n",
       "  'Authors': ['Amelia Mohd Noor',\n",
       "   'Dodi Suryana',\n",
       "   'Engku Mardiah Engku Kamarudin',\n",
       "   'Noor Banu Mahadir Naidu',\n",
       "   'Priyalatha Govindasamy'],\n",
       "  'CompanyAffiliations': {'Department of Moral, Civic Studies and Character Development, Universiti Pendidikan Sultan Idris, Tanjung Salim, Perak, Malaysia.'},\n",
       "  'CorrespondingAuthorEmail': 'amelia@fpm.upsi.edu.my.'},\n",
       " {'PubMedID': '40198009',\n",
       "  'Title': 'Factors Contributing to Well-Being Among Hospital-Based Nurses.',\n",
       "  'PublicationDate': 'N/A',\n",
       "  'Authors': ['Christine Griffin'],\n",
       "  'CompanyAffiliations': {\"The Queen's Medical Center, Caring Science & Nursing Practice and Quality Departments, Honolulu, Hawaii, USA.\"},\n",
       "  'CorrespondingAuthorEmail': 'N/A'},\n",
       " {'PubMedID': '40197340',\n",
       "  'Title': 'Staff burnout and its risk factors at King Faisal Hospital Rwanda: a cross-sectional survey.',\n",
       "  'PublicationDate': '2025-Apr-07',\n",
       "  'Authors': ['Gaston Nyirigira',\n",
       "   'Felix Rutayisire',\n",
       "   'Kara L Neil',\n",
       "   'Rulinda Kwizera',\n",
       "   'Jackson Kwizera Ndekezi',\n",
       "   'Michel R Gatera',\n",
       "   'Belise S Uwurukundo'],\n",
       "  'CompanyAffiliations': ['N/A'],\n",
       "  'CorrespondingAuthorEmail': 'gaston.nyirigira@kfhkigali.com.'},\n",
       " {'PubMedID': '40197254',\n",
       "  'Title': \"A thematic analysis of newly qualified doctors' experiences of burnout.\",\n",
       "  'PublicationDate': '2025-Apr-07',\n",
       "  'Authors': ['Colin R Kilday'],\n",
       "  'CompanyAffiliations': ['N/A'],\n",
       "  'CorrespondingAuthorEmail': 'colin.kilday@nhs.net.'},\n",
       " {'PubMedID': '40195860',\n",
       "  'Title': 'Understanding the Unmet Needs, Experiences, and Perspectives of COPD Caregivers: A Scoping Review.',\n",
       "  'PublicationDate': 'N/A',\n",
       "  'Authors': ['Elizabeth J Cooper'],\n",
       "  'CompanyAffiliations': ['N/A'],\n",
       "  'CorrespondingAuthorEmail': 'N/A'},\n",
       " {'PubMedID': '40193343',\n",
       "  'Title': 'Virtual reality for stress management and burnout reduction in nursing: A systematic review protocol.',\n",
       "  'PublicationDate': 'N/A',\n",
       "  'Authors': ['N/A'],\n",
       "  'CompanyAffiliations': ['N/A'],\n",
       "  'CorrespondingAuthorEmail': 'N/A'},\n",
       " {'PubMedID': '40190891',\n",
       "  'Title': 'Future Perspectives in Radiology: Artificial Intelligence for Responsible Imaging (AIRI).',\n",
       "  'PublicationDate': 'N/A',\n",
       "  'Authors': ['N/A'],\n",
       "  'CompanyAffiliations': ['N/A'],\n",
       "  'CorrespondingAuthorEmail': 'N/A'},\n",
       " {'PubMedID': '40189789',\n",
       "  'Title': \"'SWell' Staff Wellbeing Interventions in Paediatric Critical Care: A Feasibility Study.\",\n",
       "  'PublicationDate': 'N/A',\n",
       "  'Authors': ['Sally Crighton'],\n",
       "  'CompanyAffiliations': ['N/A'],\n",
       "  'CorrespondingAuthorEmail': 'N/A'},\n",
       " {'PubMedID': '40189735',\n",
       "  'Title': 'Healthcare worker burnout: rethinking the maslach burnout inventory.',\n",
       "  'PublicationDate': '2025-Apr-06',\n",
       "  'Authors': ['N/A'],\n",
       "  'CompanyAffiliations': ['N/A'],\n",
       "  'CorrespondingAuthorEmail': 'N/A'}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"healthcare burnout\"\n",
    "papers = fetch_all_papers(query, max_results=10)\n",
    "\n",
    "papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6e8b414a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def save_paper_details_to_csv(papers: List[Dict[str, Any]], query: str, filename: Optional[str] = None) -> None:\n",
    "    # Sanitize the query to make it a valid filename\n",
    "    sanitized_query = re.sub(r'[^\\w\\s-]', '', query)  # Remove any special characters\n",
    "    sanitized_query = re.sub(r'[-\\s]+', '_', sanitized_query).strip()  # Replace spaces and hyphens with underscores\n",
    "    \n",
    "    # Set the filename to the query if not provided\n",
    "    if not filename:\n",
    "        filename = f\"{sanitized_query}_results.csv\"\n",
    "    \n",
    "    # Create a DataFrame from the list of paper details\n",
    "    df = pd.DataFrame(papers)\n",
    "    \n",
    "    # Save the DataFrame to a CSV file\n",
    "    df.to_csv(filename, index=False, encoding='utf-8')\n",
    "    print(f\"Results saved to {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f702ba67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to healthcare_burnout_results.csv\n"
     ]
    }
   ],
   "source": [
    "# Save to CSV with dynamic filename based on the query\n",
    "save_paper_details_to_csv(papers, query=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3c17c6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-10 02:52:09,197 - DEBUG - Starting new HTTPS connection (1): eutils.ncbi.nlm.nih.gov:443\n",
      "2025-04-10 02:52:10,025 - DEBUG - https://eutils.ncbi.nlm.nih.gov:443 \"GET /entrez/eutils/esearch.fcgi?db=pubmed&term=healthcare+burnout&retmax=10&usehistory=y&retmode=xml HTTP/11\" 200 None\n",
      "2025-04-10 02:52:10,025 - DEBUG - Starting new HTTPS connection (1): eutils.ncbi.nlm.nih.gov:443\n",
      "2025-04-10 02:52:10,807 - DEBUG - https://eutils.ncbi.nlm.nih.gov:443 \"GET /entrez/eutils/efetch.fcgi?db=pubmed&id=40202386&retmode=xml HTTP/11\" 200 None\n",
      "2025-04-10 02:52:11,000 - DEBUG - Starting new HTTPS connection (1): eutils.ncbi.nlm.nih.gov:443\n",
      "2025-04-10 02:52:11,776 - DEBUG - https://eutils.ncbi.nlm.nih.gov:443 \"GET /entrez/eutils/efetch.fcgi?db=pubmed&id=40200377&retmode=xml HTTP/11\" 200 None\n",
      "2025-04-10 02:52:12,022 - DEBUG - Starting new HTTPS connection (1): eutils.ncbi.nlm.nih.gov:443\n",
      "2025-04-10 02:52:12,792 - DEBUG - https://eutils.ncbi.nlm.nih.gov:443 \"GET /entrez/eutils/efetch.fcgi?db=pubmed&id=40198009&retmode=xml HTTP/11\" 200 None\n",
      "2025-04-10 02:52:12,988 - DEBUG - Starting new HTTPS connection (1): eutils.ncbi.nlm.nih.gov:443\n",
      "2025-04-10 02:52:13,802 - DEBUG - https://eutils.ncbi.nlm.nih.gov:443 \"GET /entrez/eutils/efetch.fcgi?db=pubmed&id=40197340&retmode=xml HTTP/11\" 200 None\n",
      "2025-04-10 02:52:13,931 - DEBUG - Starting new HTTPS connection (1): eutils.ncbi.nlm.nih.gov:443\n",
      "2025-04-10 02:52:15,172 - DEBUG - https://eutils.ncbi.nlm.nih.gov:443 \"GET /entrez/eutils/efetch.fcgi?db=pubmed&id=40197254&retmode=xml HTTP/11\" 200 None\n",
      "2025-04-10 02:52:15,417 - DEBUG - Starting new HTTPS connection (1): eutils.ncbi.nlm.nih.gov:443\n",
      "2025-04-10 02:52:16,197 - DEBUG - https://eutils.ncbi.nlm.nih.gov:443 \"GET /entrez/eutils/efetch.fcgi?db=pubmed&id=40195860&retmode=xml HTTP/11\" 200 None\n",
      "2025-04-10 02:52:16,197 - DEBUG - Starting new HTTPS connection (1): eutils.ncbi.nlm.nih.gov:443\n",
      "2025-04-10 02:52:16,959 - DEBUG - https://eutils.ncbi.nlm.nih.gov:443 \"GET /entrez/eutils/efetch.fcgi?db=pubmed&id=40193343&retmode=xml HTTP/11\" 200 None\n",
      "2025-04-10 02:52:17,207 - DEBUG - Starting new HTTPS connection (1): eutils.ncbi.nlm.nih.gov:443\n",
      "2025-04-10 02:52:17,984 - DEBUG - https://eutils.ncbi.nlm.nih.gov:443 \"GET /entrez/eutils/efetch.fcgi?db=pubmed&id=40190891&retmode=xml HTTP/11\" 200 None\n",
      "2025-04-10 02:52:18,168 - DEBUG - Starting new HTTPS connection (1): eutils.ncbi.nlm.nih.gov:443\n",
      "2025-04-10 02:52:18,906 - DEBUG - https://eutils.ncbi.nlm.nih.gov:443 \"GET /entrez/eutils/efetch.fcgi?db=pubmed&id=40189789&retmode=xml HTTP/11\" 200 None\n",
      "2025-04-10 02:52:19,092 - DEBUG - Starting new HTTPS connection (1): eutils.ncbi.nlm.nih.gov:443\n",
      "2025-04-10 02:52:19,843 - DEBUG - https://eutils.ncbi.nlm.nih.gov:443 \"GET /entrez/eutils/efetch.fcgi?db=pubmed&id=40189735&retmode=xml HTTP/11\" 200 None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to results.csv\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import argparse\n",
    "import logging\n",
    "\n",
    "# Define your other functions here (fetch_paper_ids_from_pubmed, fetch_all_papers, etc.)\n",
    "\n",
    "def setup_logging(debug: bool):\n",
    "    logging.basicConfig(\n",
    "        level=logging.DEBUG if debug else logging.INFO,\n",
    "        format='%(asctime)s - %(levelname)s - %(message)s'\n",
    "    )\n",
    "\n",
    "def main():\n",
    "    # Simulate command-line arguments for Jupyter Notebook\n",
    "    sys.argv = ['your_script.py', 'healthcare burnout', '--debug', '--file', 'results.csv']\n",
    "\n",
    "    # Argument parsing setup\n",
    "    parser = argparse.ArgumentParser(description=\"Fetch PubMed papers based on a query\")\n",
    "    parser.add_argument(\"query\", type=str, help=\"Search query to fetch papers from PubMed\")\n",
    "    parser.add_argument(\"-d\", \"--debug\", action=\"store_true\", help=\"Enable debug logging\")\n",
    "    parser.add_argument(\"-f\", \"--file\", type=str, help=\"Specify the filename to save the results\")\n",
    "\n",
    "    # Parse the arguments\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Set up logging based on the debug flag\n",
    "    setup_logging(debug=args.debug)\n",
    "\n",
    "    # Fetch the papers based on the query\n",
    "    papers = fetch_all_papers(args.query, max_results=10)\n",
    "\n",
    "    # Save the results to a file or print them to the console\n",
    "    if args.file:\n",
    "        save_paper_details_to_csv(papers, query=args.query, filename=args.file)\n",
    "    else:\n",
    "        print(papers)\n",
    "\n",
    "# Run the main function\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a38bc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
